# job settings
job_script="./scripts/distributed/train.sh"

# task settings
model=UnifiedTransformer
task=DialogGeneration

vocab_path="./projects/lic2021/conf/vocab.txt"
spm_model_file="./projects/lic2021/conf/spm.model"
train_file="./data/lic2021/train.shuffle.txt"
valid_file="./data/lic2021/valid.txt"
data_format="numerical"
file_format="file"
config_path="./projects/lic2021/conf/12L.json"

# training settings
init_params="./data/lic2021/12L.pretrain"
in_tokens="true"
batch_size=8192
lr=1e-5
warmup_steps=4000
weight_decay=0.01

train_args="--max_src_len 384 --max_tgt_len 128 --max_seq_len 512"

num_epochs=10
log_steps=10
validation_steps=1000
save_steps=1000

log_dir="./projects/lic2021/train/log"
save_path="./projects/lic2021/train/output"
